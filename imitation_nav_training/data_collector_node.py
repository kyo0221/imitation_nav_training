import os
import sys
import rclpy
from rclpy.node import Node
from std_msgs.msg import Empty, Bool, String
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist

from cv_bridge import CvBridge
import cv2
import numpy as np
import matplotlib.pyplot as plt
import webdataset as wds
import io
import json
import time
import threading

from .topomap_creator_node import TopologicalMapCreator
from .placenet import PlaceNet


class DataCollector(Node):
    def __init__(self):
        super().__init__('data_collector')
        pkg_dir = os.path.dirname(os.path.realpath(__file__))

        self.declare_parameter('image_topic', '/image_raw')
        self.declare_parameter('cmd_vel_topic', '/cmd_vel')
        self.declare_parameter('image_width', 200)
        self.declare_parameter('image_height', 88)
        self.declare_parameter('log_name', 'dataset')
        self.declare_parameter('max_data_count', 50000)
        self.declare_parameter('save_node_freq', 5)
        self.declare_parameter('show_histogram', True)
        self.declare_parameter('samples_per_shard', 1000)
        self.declare_parameter('enable_compression', True)

        self.image_topic = self.get_parameter('image_topic').get_parameter_value().string_value
        self.cmd_vel_topic = self.get_parameter('cmd_vel_topic').get_parameter_value().string_value
        self.img_width = self.get_parameter('image_width').get_parameter_value().integer_value
        self.img_height = self.get_parameter('image_height').get_parameter_value().integer_value
        self.log_name = self.get_parameter('log_name').get_parameter_value().string_value
        self.max_data_count = self.get_parameter('max_data_count').get_parameter_value().integer_value
        self.save_node_freq = self.get_parameter('save_node_freq').get_parameter_value().integer_value
        self.show_histogram = self.get_parameter('show_histogram').get_parameter_value().bool_value
        self.samples_per_shard = self.get_parameter('samples_per_shard').get_parameter_value().integer_value
        self.enable_compression = self.get_parameter('enable_compression').get_parameter_value().bool_value

        self.save_log_path = os.path.join(pkg_dir, '..', 'logs')
        self.dataset_dir = os.path.join(self.save_log_path, self.log_name)
        self.webdataset_dir = os.path.join(self.dataset_dir, 'webdataset')
        os.makedirs(self.webdataset_dir, exist_ok=True)

        self.topo_map_dir = os.path.join(self.save_log_path, 'topo_map')
        os.makedirs(self.topo_map_dir, exist_ok=True)
        self.topo_map_yaml = os.path.join(self.topo_map_dir, 'topomap.yaml')
        self.image_dir = os.path.join(self.topo_map_dir, 'images')
        os.makedirs(self.image_dir, exist_ok=True)
        self.weight_path = os.path.join(pkg_dir, '..', 'weights', 'efficientnet_85x85.pth')
        self.map_creator = TopologicalMapCreator(self.topo_map_yaml, self.image_dir, self.weight_path)

        self.bridge = CvBridge()
        self.last_ang_vel = 0.0
        self.command_mode = "roadside"
        self.action_to_index = {"roadside": 0, "straight": 1, "left": 2, "right": 3}
        self.save_flag = False
        self.image_save_counter = 1
        self.data_count = 0
        self.action_counts = {"roadside": 0, "straight": 0, "left": 0, "right": 0}
        
        # WebDatasetç”¨ã®è¨­å®š
        self.current_shard = 0
        self.current_shard_count = 0
        self.shard_writer = None
        self.total_data_size = 0
        self.shard_lock = threading.Lock()  # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã®ãŸã‚ã®ãƒ­ãƒƒã‚¯
        self._last_processed_image = None
        
        # ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
        self.completed_shards = []
        
        self._init_shard_writer()
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤ºç”¨ã®å›³ã‚’åˆæœŸåŒ–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        self.fig = None
        self.ax = None
        if self.show_histogram:
            try:
                plt.ion()  # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ON
                self.fig, self.ax = plt.subplots(figsize=(10, 6))
            except Exception as e:
                self.get_logger().warn(f"ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤ºã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                self.show_histogram = False

        self.image_sub = self.create_subscription(Image, self.image_topic, self.image_callback, 10)
        self.cmd_sub = self.create_subscription(Twist, self.cmd_vel_topic, self.cmd_callback, 10)
        self.cmd_route_sub = self.create_subscription(String, "/cmd_route", self.command_mode_callback, 10)
        self.cmd_save_image_sub = self.create_subscription(Empty, "/save_image", self.save_image_callback, 10)
        self.save_flag_sub = self.create_subscription(Bool, '/save', self.save_callback, 10)

        self.get_logger().info(f"Saving webdataset to: {self.webdataset_dir}")
        self.get_logger().info(f"Samples per shard: {self.samples_per_shard}")
        self.get_logger().info(f"Compression enabled: {self.enable_compression}")
        self.get_logger().info("Save format: numpy array")
        self.create_timer(self.save_node_freq, self.save_topomap_periodic)

    def _get_shard_filename(self, shard_id):
        """ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
        if self.enable_compression:
            return os.path.join(self.webdataset_dir, f"shard_{shard_id:06d}.tar.gz")
        else:
            return os.path.join(self.webdataset_dir, f"shard_{shard_id:06d}.tar")

    def _close_current_shard_and_start_next(self):
        """ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é–‰ã˜ã¦æ¬¡ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é–‹å§‹"""
        with self.shard_lock:
            # WebDatasetã®ShardWriterã¯è‡ªå‹•ã§ã‚·ãƒ£ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚’è¡Œã†
            # æ‰‹å‹•ã§ã®ã‚·ãƒ£ãƒ¼ãƒ‰ç®¡ç†ã‚’ã‚„ã‚ã¦ã€WebDatasetã«ä»»ã›ã‚‹
            self.current_shard += 1
            self.current_shard_count = 0
            self.get_logger().info(f"ğŸ—‚ï¸ ã‚·ãƒ£ãƒ¼ãƒ‰ {self.current_shard-1} ãŒæº€æ¯ã«ãªã‚Šã¾ã—ãŸã€‚WebDatasetãŒè‡ªå‹•ã§æ¬¡ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")

    def _init_shard_writer(self):
        """æœ€åˆã®ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ©ã‚¤ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–"""
        with self.shard_lock:
            try:
                # WebDatasetã®ShardWriterã¯%å½¢å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æœŸå¾…ã™ã‚‹
                if self.enable_compression:
                    shard_pattern = os.path.join(self.webdataset_dir, "shard_%06d.tar.gz")
                else:
                    shard_pattern = os.path.join(self.webdataset_dir, "shard_%06d.tar")
                
                self.shard_writer = wds.ShardWriter(shard_pattern, maxcount=self.samples_per_shard)
                self.current_shard_count = 0
                
                # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¡¨ç¤ºç”¨ã«ç”Ÿæˆ
                actual_filename = shard_pattern % self.current_shard
                self.get_logger().info(f"ğŸ—‚ï¸ åˆæœŸã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é–‹å§‹: {actual_filename} (maxcount={self.samples_per_shard})")
                
            except Exception as e:
                self.get_logger().error(f"åˆæœŸã‚·ãƒ£ãƒ¼ãƒ‰ãƒ©ã‚¤ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                self.save_error_count += 1
                self.shard_writer = None

    def _get_current_shard_size(self):
        """ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã®ã‚µã‚¤ã‚ºã‚’å–å¾—"""
        shard_filename = self._get_shard_filename(self.current_shard)
        
        try:
            if os.path.exists(shard_filename):
                return os.path.getsize(shard_filename)
            else:
                return 0
        except OSError as e:
            self.get_logger().warn(f"ã‚·ãƒ£ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def _log_data_stats(self):
        """ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›"""
        current_shard_size = self._get_current_shard_size()
        
        self.get_logger().info(
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ: "
            f"åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°={self.data_count}, "
            f"ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰={self.current_shard}, "
            f"ã‚·ãƒ£ãƒ¼ãƒ‰å†…ã‚µãƒ³ãƒ—ãƒ«æ•°={self.current_shard_count}, "
            f"ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚µã‚¤ã‚º={current_shard_size / 1024:.2f}KB, "
            f"å®Œäº†ã—ãŸã‚·ãƒ£ãƒ¼ãƒ‰æ•°={len(self.completed_shards)}"
        )

    def cmd_callback(self, msg):
        self.last_ang_vel = msg.angular.z

    def command_mode_callback(self, msg):
        if msg.data in self.action_to_index:
            self.command_mode = msg.data
        else:
            self.get_logger().warn(f"Unknown command: {msg.data}, using 'roadside' instead.")
            self.command_mode = "roadside"

    def save_callback(self, msg):
        if msg.data:
            self.save_flag = True
            self.get_logger().info("Save flag received, starting data collection.")
        else:
            self.save_flag = False
            self.get_logger().info("Save flag disabled, stopping data collection.")

    def image_callback(self, msg):
        if not self.save_flag:  return

        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        resized = cv2.resize(cv_image, (self.img_width, self.img_height))

        # æœ€å¾Œã«å‡¦ç†ã—ãŸç”»åƒã‚’è¨˜éŒ²ï¼ˆTopoMapç”¨ï¼‰
        self._last_processed_image = resized.copy()

        # WebDatasetå½¢å¼ã§ä¿å­˜
        save_success = self._save_webdataset_sample(resized, self.last_ang_vel, self.action_to_index[self.command_mode], msg)
        
        if save_success:
            self.action_counts[self.command_mode] += 1
            self.data_count += 1
            self.current_shard_count += 1
            
            # ã‚·ãƒ£ãƒ¼ãƒ‰ãŒæº€æ¯ã«ãªã£ãŸã‚‰æ–°ã—ã„ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’é–‹å§‹
            # WebDatasetã®ShardWriterãŒè‡ªå‹•ã§ã‚·ãƒ£ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚’è¡Œã†ãŸã‚ã€ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®ãƒªã‚»ãƒƒãƒˆã®ã¿
            if self.current_shard_count >= self.samples_per_shard:
                self._close_current_shard_and_start_next()
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’å®šæœŸçš„ã«æ›´æ–°
            if self.save_flag and self.show_histogram and self.data_count % 10 == 0:    self.display_histogram()
            if self.data_count % 100 == 0:  self._log_data_stats()
            if self.data_count % 10 == 0:   self.get_logger().info(f"ğŸ“¸ Sample saved: {self.data_count:05d}")
        else:
            self.get_logger().warn("ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")


    def _save_webdataset_sample(self, image, angle, action, msg):
        if self.shard_writer is None:
            self.get_logger().error("ShardWriter is not initialized")
            return False
        
        try:
            with self.shard_lock:
                img_buffer = io.BytesIO()
                np.save(img_buffer, image)
                img_data = img_buffer.getvalue()
                img_ext = "npy"
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                metadata = {
                    'angle': float(angle),
                    'action': int(action),
                    'timestamp': msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9 if hasattr(msg, 'header') else time.time(),
                    'image_width': self.img_width,
                    'image_height': self.img_height,
                    'save_format': 'numpy',
                    'image_shape': list(image.shape),
                    'image_dtype': str(image.dtype),
                }
                
                # WebDatasetã«æ›¸ãè¾¼ã¿
                sample_key = f"{self.data_count:06d}"
                sample_data = {
                    "__key__": sample_key,
                    img_ext: img_data,
                    "metadata.json": json.dumps(metadata),
                    "action.json": json.dumps({"action": int(action), "angle": float(angle)})
                }
                
                self.shard_writer.write(sample_data)
                return True
                
        except Exception as e:
            self.get_logger().error(f"WebDatasetä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def save_image_callback(self, msg: Empty):
        self.save_topomap_image()

    def save_topomap_image(self):
        if self.data_count == 0:
            self.get_logger().warn("No image available yet for topomap.")
            return

        try:
            dst_name = f"{self.image_save_counter:05d}.png"
            dst_path = os.path.join(self.image_dir, dst_name)
            
            if self._last_processed_image is not None:
                resized_img = cv2.resize(self._last_processed_image, (85, 85))
                bgr_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2BGR) # rgb to bgr
                cv2.imwrite(dst_path, bgr_img)
                self.map_creator.add_node(dst_name, self.command_mode)
                self.image_save_counter += 1
                self.get_logger().info(f"ğŸ—ºï¸ Topomap image saved: {dst_name}")
            else:
                self.get_logger().warn("No processed image available for topomap")
                
        except Exception as e:
            self.get_logger().error(f"[save_topomap_image] Failed to save topomap image: {e}")

    def save_topomap_periodic(self):
        if self.save_flag and self.data_count > 0:
            self.save_topomap_image()

    def display_histogram(self):
        """ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’è¡¨ç¤º"""
        if not self.show_histogram or self.fig is None or self.ax is None:
            return
            
        try:
            actions = list(self.action_counts.keys())
            counts = list(self.action_counts.values())
            
            # æ—¢å­˜ã®å›³ã‚’ã‚¯ãƒªã‚¢ã—ã¦æ›´æ–°
            self.ax.clear()
            
            bars = self.ax.bar(actions, counts, color=['orange', 'blue', 'green', 'red'])
            self.ax.set_xlabel('Action Type')
            self.ax.set_ylabel('Count')
            self.ax.set_title(f'Data Collection Histogram (Total: {self.data_count})')
            
            for bar, count in zip(bars, counts):
                height = bar.get_height()
                self.ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                            f'{count}', ha='center', va='bottom')
            
            # å›³ã‚’æ›´æ–°ã—ã¦è¡¨ç¤º
            self.fig.canvas.draw()
            self.fig.canvas.flush_events()
            plt.pause(0.001)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            histogram_path = os.path.join(self.dataset_dir, 'data_histogram.png')
            self.fig.savefig(histogram_path)
            
        except Exception as e:
            self.get_logger().warn(f"ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_dataset_stats(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜"""
        # æœ€çµ‚ã‚·ãƒ£ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(os.path.getsize(shard) for shard in self.completed_shards if os.path.exists(shard))
        current_shard_size = self._get_current_shard_size()
        total_size += current_shard_size
        
        stats = {
            "total_samples": self.data_count,
            "total_shards": len(self.completed_shards) + (1 if self.current_shard_count > 0 else 0),
            "completed_shards": len(self.completed_shards),
            "current_shard_samples": self.current_shard_count,
            "samples_per_shard": self.samples_per_shard,
            "compression_enabled": self.enable_compression,
            "save_format": "numpy",
            "action_distribution": dict(self.action_counts),
            "dataset_directory": self.webdataset_dir,
            "image_size": [self.img_height, self.img_width],
            "max_data_count": self.max_data_count,
            "total_dataset_size_bytes": total_size,
            "save_error_count": self.save_error_count,
            "shard_files": [
                {"filename": os.path.basename(shard), "size": os.path.getsize(shard)}
                for shard in self.completed_shards if os.path.exists(shard)
            ]
        }
        
        # ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚‚è¿½åŠ 
        if self.current_shard_count > 0:
            current_shard_file = self._get_shard_filename(self.current_shard)
            if os.path.exists(current_shard_file):
                stats["shard_files"].append({
                    "filename": os.path.basename(current_shard_file),
                    "size": os.path.getsize(current_shard_file)
                })
        
        stats_file = os.path.join(self.webdataset_dir, "dataset_stats.json")
        try:
            with open(stats_file, 'w') as f:
                json.dump(stats, f, indent=2)
            self.get_logger().info(f"ğŸ“Š çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: {stats_file}")
        except Exception as e:
            self.get_logger().error(f"çµ±è¨ˆæƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def destroy_node(self):
        """ãƒãƒ¼ãƒ‰ã‚’å®‰å…¨ã«çµ‚äº†"""
        self.get_logger().info("ğŸ›‘ ãƒ‡ãƒ¼ã‚¿åé›†ãƒãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã™...")
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’æœ€çµ‚æ›´æ–°
        if self.show_histogram:
            try:
                self.display_histogram()
                if self.fig is not None:
                    plt.close(self.fig)
                    self.fig = None
            except:
                pass
        
        # WebDatasetã®ä¿å­˜ã‚’å®Œäº†
        if self.shard_writer is not None:
            self._log_data_stats()
            try:
                with self.shard_lock:
                    self.shard_writer.close()
                    final_shard = self._get_shard_filename(self.current_shard)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®åŒæœŸã‚’å¾…ã¤
                    
                    if os.path.exists(final_shard):
                        self.completed_shards.append(final_shard)
                        file_size = os.path.getsize(final_shard)
                        self.get_logger().info(f"ğŸ—‚ï¸ æœ€çµ‚ã‚·ãƒ£ãƒ¼ãƒ‰ {self.current_shard} ã‚’ä¿å­˜: {final_shard} ({file_size} bytes)")
                    else:
                        self.get_logger().warn(f"âš ï¸ æœ€çµ‚ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {final_shard}")
            except Exception as e:
                self.get_logger().error(f"æœ€çµ‚ã‚·ãƒ£ãƒ¼ãƒ‰ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµ±è¨ˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        self._save_dataset_stats()
        
        # å®Œäº†ã—ãŸã‚·ãƒ£ãƒ¼ãƒ‰ã®ä¸€è¦§ã‚’è¡¨ç¤º
        self.get_logger().info(f"ğŸ—‚ï¸ å®Œäº†ã—ãŸã‚·ãƒ£ãƒ¼ãƒ‰æ•°: {len(self.completed_shards)}")
        for i, shard in enumerate(self.completed_shards):
            if os.path.exists(shard):
                size = os.path.getsize(shard)
                self.get_logger().info(f"  {i+1}. {os.path.basename(shard)} ({size} bytes)")
        
        # TopoMapã‚’ä¿å­˜
        try:
            self.map_creator.save_map()
            self.get_logger().info("ğŸ—ºï¸ TopoMapä¿å­˜å®Œäº†")
        except Exception as e:
            self.get_logger().error(f"TopoMapä¿å­˜ã‚¨ãƒ©ãƒ¼")
        
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = DataCollector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("\n[INFO] Graceful shutdown by Ctrl+C.")
    finally:
        node.destroy_node()
        rclpy.shutdown()
        sys.exit(0)